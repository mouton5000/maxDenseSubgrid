
\section{Heuristics}
\label{sect:heuristics}

In this section, we describe four natural heuristics for MMC : two first-come-first-served algorithm and two greedy algorithms.

\subsection{The LCL heuristic}

This algorithm is a first-come-first-served algorithm. It is divided into two parts: the Line-Column (LC) part and the Column-Line (CL) part. 

The LC part computes and returns a maximal feasible solution $M^{LC}$ by, firstly, contracting a maximal set of lines $I^{LC}$ and, then, by contracting a maximal set of columns $J^{LC}$. The algorithm builds $I^{LC}$ as follows: it checks for each line from $p-1$ down to $1$ if the contraction of that line is legal. In that case, the contraction is done and the algorithm goes on. $J^{LC}$ is built the same way.

The CL part computes and returns a maximal feasible solution $M^{CL}$ by starting with the columns and ending with the lines. The LCL algorithm then returns the solution with the maximum density.

The advantage of such an algorithm is its time complexity due to its simplicity.

\begin{theorem}
	The time complexity of the LCL algorithm is $O(p \cdot q)$. 
\end{theorem}
\begin{proof}
	The four sets $I^{LC}$, $J^{LC}$, $I^{CL}$ and $J^{CL}$ can be implemented in time $O(p \cdot q)$ using an auxiliary matrix $M'$. The proof is given for the first one, the implementation of the three other ones is similar. At first, we copy $M$ into $M'$. For each line $i$ from $p-1$ to $1$ of $M'$, we check with $2q$ comparison if there is a column $j$ such that $M'_{i,j} = M'_{i+1,j} = 1$. In that case, we do nothing. Otherwise, we add $i$ to $I^{LC}$, we sum the $i$-th and the $i+1$-th lines and we replace line $i$ with the result.
	
	Finally, given a matrix $M$ and a set of lines $I$, one can compute $C(M,I,\emptyset)$ in time $O(p \cdot q)$ by, firstly, computing in time $O(p)$ an array $A$ of size $p$ such that $A_i$ is the number of lines in $I$ strictly lower than $i$ and, secondly, returning a matrix $C$ of size $p - |I| \times q$ such that $C_{i-A_i,j} = M{i,j}$.
\end{proof}

\begin{remark}
	Note that, if there is at most one 1 per line of the matrix of the matrix, the LCL algorithm is asymptotically a 4-approximation when $n$ approaches infinity. Indeed, the LC part returns a line matrix in which each entry is a 1. The density of this solution is $n-1$. As the maximum density is $4n$ by Lemma~\ref{lem:bounds}, the ratio is $4\frac{n}{n-1}$. 
\end{remark} 

\begin{remark}
	On the contrary, if we consider the instances in which there are lines and columns containing two 1, this algorithm is at least $\sqrt{n}$-approximation algorithm. This is due to the incompatibility between lines or columns. For example if $M_{i,j} = M{i+2,j} = 1$, one can contract either line $i$ or line $i+1$ but not the two of them. We can use this property adapt the instance of Figure~\ref{fig:badinstance} in order to lure the algorithm.
\end{remark}

\subsection{The greedy algorithm}

The greedy algorithm tries to maximize the density at each iteration. 

The algorithm computes $d(C(M,\{i\},\emptyset))$ and $d(C(M,\emptyset, \{j\}))$ for each line $i$ and each column $j$ if the contraction is legal. It then chooses the line or the column maximizing the density. It starts again until the solution is maximal.

\begin{theorem}
	The time complexity of the Greedy algorithm is $O(p^2 \cdot q^2)$. 
\end{theorem}
\begin{proof}
	There are at most $p \cdot q$ iterations. At each iteration, we computes one density per line $i$ and one density per column $j$. The density of $C(M,\{i\},\emptyset)$ is the density of $M$ plus the number of new neighbor pairs of 1 due to the contraction of lines $i$ and $i+1$. The increment can be computing in time $O(q)$ as there are at most three new neighbors for each of the $q$ entries of the four lines $i-1$ to $i+2$. Similarly, the density of $C(M,\emptyset,\{j\})$ can be computing in time $O(p)$. Thus one iteration takes $O(p \cdot q)$ iterations. 
\end{proof}

\begin{remark}
	As for the LCL algorithm, this algorithm is also at least a $\sqrt{n}$-approximation algorithm as we can adapt the instance of Figure~\ref{fig:badinstance} in order to lure the greedy algorithm. Indeed, we can force the algorithm to choose a line or a column by making it the sole choice increasing the density.
\end{remark}

\subsection{The neighborization algorithm}

The neighborization algorithm is a greedy algorithm trying to maximize, at each iteration, the number of couple of entries that can be moved next to each other with a contraction.

We define a function $N$ from $(\llbracket 0;p-1 \rrbracket \times \llbracket 0;q-1 \rrbracket)^2$ to $\{0,1\}$.
For each couple $c = ((i,j),(i',j'))$ such that $M_{i,j} = 0$ or $M_{i',j'} = 0$, $N(c) = 0$. Otherwise, $N(c) = 1$ if and only if there is a sublist of lines $I$ and a sublist of columns $J$ such that $C(M,I,J)$ is legal and such that the two entries are moved next to each other with this contraction. Finally, we define $$N(M) = \sum\limits_{i = 1}^p\sum\limits_{j = 1}^q\sum\limits_{i' = 1}^p\sum\limits_{j' = 1}^q N((i,j),(i',j'))$$

The algorithm computes $N(C(M,\{i\},\emptyset))$ and $N(C(M,\emptyset, \{j\}))$ for each line $i$ and each column $j$ if the contraction is legal. It then chooses the line or the column maximizing the result. It starts again until the solution is maximal.

\begin{theorem}
	The time complexity of the Greedy algorithm is $O(n^2 \cdot p^3 \cdot q^3 \cdot (p+q))$. 
\end{theorem}
\begin{proof}
	Let $M$ be a binary matrix, we first determine the time complexity we need to compute $N(M)$. Let $((i,j),(i',j'))$ be two coordinates such that $M_{i,j} = M_{i',j'} = 1$. We assume $i < i'$ and $j < j'$. The two entries may be moved next to each other if $i'- i -1$ of the $i'-i$ lines and $j'- j -1$ of the $j'-j$ columns between the two entries may be contracted and this can be done in time $O(p \cdot q \cdot (j'-j) \cdot (i'-i)) = O(p^2 \cdot q^2)$. As there are at most $n^2$ entries satisfying $M_{i,j} = M_{i',j'} = 1$, we need $O(n^2 \cdot p^2 \cdot q^2)$ operations to compute $N(M)$.  
	
	As there are at most $p \cdot q$ iterations. At each iteration, we computes one value per line $i$ and one value per column $j$ in time $O(n^2 \cdot p^2 \cdot q^2)$. The time complexity is then $O(n^2 \cdot p^3 \cdot q^3 \cdot (p+q))$.
\end{proof}

\subsection{Numerical results}

In this last subsection, we implemented the three algorithms in order to evaluate their performances.

The tests were done on an Intel(R) Core(TM) i7-4810MQ CPU @ 2.80GHz processor with 8Go of RAM. The implementations were done using Java 8 and can be found at \url{https://github.com/mouton5000/MMCCode}.

